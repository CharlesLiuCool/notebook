In history mathematicians have searched for a single quantity that determines the invertibility of a matrix

#### Motivations:

For an $large{n \times n}$ matrix with $\large{n = 1}$ or $\large{n = 2}$ we have such a quantity that can help us determine the invertibility of the matrix

>$\large{n = 1}$   $\large{A = [a_n]}$ is invertible$\large{\iff \det(A) = a_n \neq 0 \text{ and } A^{-1} = \left[\frac{1}{a_n}\right]}$

>$\large{n = 2}$   $\large{\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}}$ invertible $\begin{align} \large{\iff \det(A) = a_n \neq 0} \end{align}$ and $$$$$\large{A^{-1} = [\frac{1}{a_n}]}$

Lets see how the determinant is defined for a $\large{2 \times 2}$ matrix

Before doing that, we need to introduce a notion.
___________________________________________________________________
### Definition 1.

Let $A = [a_{ij}]_{n*n}$ with $n \geq 2$. The cofactor of $a_{ij}$ is $\large{(-1)^{i+j}\det(A_{ij})}$, where $A_{ij}$ is the $(n-1) * (n-1)$ matrix obtained from $A$ by deleting the row $i$ and column $j$. For simplicity, we denote the cofactor of $a_{ij}$ by $C_{ij}$.

Step 1: Compute the cofactors $C_{ij}$ along the first row - but we need to be careful of the sign! Always start positive in the first entry of the matrix
$$$\large{ \begin{align} &\;\;\;2 \times 2 \\ &\begin{bmatrix} + & - \\ - & + \end{bmatrix}\end{align}}$$
$$\large{\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22}\end{bmatrix} \;\;\;\;\;\;\;\;\;\;\;\;\;\; C_{11} \;is\; a_{22}}$$
$$\large{\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22}\end{bmatrix} \;\;\;\;\;\;\;\;\;\;\;\;\;\; C_{11} \;is\; a_{22}}$$
Step 2: Find the sum of cofactor expansion

Then

$$\large{\begin{align}\det(\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}) & = a_{11} \times (\text{cofactor of }a_{11}) + a_{12} \times (\text{cofactor of }a_{12}) \\ \\ &= a_{11} \times C_{11} + a_{12} * C_{12} \\ \\ &= a_{11} \times a_{22} + a_{12} \times  (-a_{21}) = a_{11} \times a_{22} - a_{12}*a_{21}\end{align}}$$
>$\large{n = 3}$   Indeed $\large{A = \begin{bmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{bmatrix}}$ invertible $\large{\iff \det(A) \neq 0}$

___________________________________________________________________
### Question:
How do you compute the determinant of a $\large{3 \times 3}$ matrix.

### Answer:
The idea is to use the determinant of some $\large{2 \times 2}$ matrices as a building block to compute the determinant of a $\large{3 \times 3}$ matrix

Let's explain this idea using an example.

___________________________________________________________________
### Example 1.

>[!example]
> Find the determinant of $\large{A = \begin{bmatrix} 1 & 0 & 2 \\ 3 & 4 & 0 \\ 2 & 1 & 1 \end{bmatrix}}$
##### Solution: 

> [!success]- Solution
> Step 1: Compute the cofactors $C_{ij}$ along the first row - but we need to be careful about the sign!

$$\large{\begin{bmatrix} + & - & + \\ - & + & - \\ + & - & + \end{bmatrix}}$$

#### Tags

>[!quote] Tags:
> [[Linear Algebra Information|Linear Algebra Information]]

