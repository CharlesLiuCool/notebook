
Let $\large{A} = 2 \times 2$ matrix, $\large{x \in \mathbb{R}}$ column vector

```desmos-graph
left=-1; right=5;
top=7; bottom=-1;
---
(1,3)| hidden| label:Ax | RED
y = 2x | x > 0 | x < 3 | RED
| y = x | x < 3 | x > 0 | label: x | BLACK

```


```desmos-graph
left=-1; right=7;
top=7; bottom=-1;
---
(1,3)| hidden| label:Ax | RED
y = x | x > 0 | x < 6 | RED
| y = x | x < 3 | x > 0 | label: x | BLACK

```

### Example 1.

Let $\large{A = \begin{bmatrix} -3 & 2 \\ 4 & -5\end{bmatrix}}$ and $\large{x = \begin{bmatrix} \,1\, \\ 1\end{bmatrix}}$

We see that 

$\large{Ax = \begin{bmatrix} -3 & 2 \\ 4 & -5\end{bmatrix}\begin{bmatrix} 1 \\ -1 \end{bmatrix} = \begin{bmatrix} \,(-3) \times 1\;+\;2 \times 1 \\ \,4 \times 1\;+\;(-5) \times 1 \end{bmatrix} = \begin{bmatrix} \,-1\, \\ -1 \end{bmatrix} = (-1) \times \begin{bmatrix} 1 \\ \,1\,\end{bmatrix}}$

Thus,

$$\large{Ax = -x}$$
___

### Definition 1.

Let $\large{A}$ be an $\large{n \times n}$ matrix and $\large{x}$ be a *nonzero vector* in $\large{\mathbb{R}^n}$ such that

$$\large{ Ax = \lambda x}$$
for some scalar $\large{\lambda}$. Then $\large{\lambda}$ is called an *eigenvalue* of A, and $\large{x}$ is called an *eigenvector* of A corresponding to the eigenvalue $\large{\lambda}$.

#### Remark 1.

1. *"Eigen"* in German means "self" or "own.
2. Traditionally, we denote eigenvalues with lowercase Greek letters due to the application of eigenvalues in physics (in a vibrating system, eigenvalues may correspond to frequencies or wavelengths)
3. In the definition, every eigenvalue must be *nonzero vector*!

___

#### Case 1.

When an eigenvector is given, it's easy to find its corresponding eigenvalue.

### Example 2.

Let $\large{A = \begin{bmatrix} 3 & 0 & 2 & 0 \\ 1 & 3 & 1 & 0 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 4 \end{bmatrix}}$. Let $\large{x = \begin{bmatrix} 2 \\ 3 \\ 1 \\ 0\end{bmatrix}}$ be an eigenvector of A. What is the 

corresponding eigenvalue?

#### Solution:

$\large{Ax = \begin{bmatrix} \,3 & 0 & 2 & 0\, \\ 1 & 3 & 1 & 0 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 4 \end{bmatrix} \begin{bmatrix} \,2\, \\ 3 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} 8 \\ 12 \\ 4 \\ 0 \end{bmatrix} = 4 \times \begin{bmatrix} \,2\, \\ 3 \\ 1 \\ 0 \end{bmatrix} = 4x}$

So $\large{\lambda = 4}$ is the corresponding eigenvalue.

___

#### Case 2.

When an eigenvalue is given, finding its eigenvector is also easy.

### Example 3.

Let $\large{A = \begin{bmatrix} 1 & 3 \\ 2 & 2 \end{bmatrix}}$ has an eigenvalue 4. Find $\large{x \neq 0}$ such that $\large{Ax = 4x}$ (i.e., find an eigenvector corresponding to $\large{\lambda = 4}$).

#### Solution:

$\large{Ax = 4x \Rightarrow Ax - 4x = 0 \Rightarrow (A - 4I)\times x = 0}$ 

We want to find a *nontrivial solution* (i.e. nonzero solution) to $\large{(A - 4I)x = 0}$

>**Note:** $$\large{\begin{align}A - 4I &= \begin{bmatrix} 1 & -3 \\ 2 & 2 \end{bmatrix} - 4 \times \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 3 \\ 2 & 2 \end{bmatrix} - \begin{bmatrix} 4 & 0 \\ 0 & 4\end{bmatrix} = \begin{bmatrix} 1-4 & 3-0 \\ 2-0 & 2-4 \end{bmatrix} \\ \\ &= \begin{bmatrix} -3 & 3 \\ 2 & -2 \end{bmatrix}\end{align}}$$

Augmented matrix

$$\large{\begin{align}&[A - 4I\;|\;0 ] = \begin{bmatrix} -3 & 3 & | & 0 \\ 2 & -2 & | & 0 \end{bmatrix} \xrightarrow{\huge{R_1\;\rightarrow \; R_1 \times (-\frac{1}{3} )}} \begin{bmatrix} 1 & -1 & | & 0 \\ 2 & -2 & | & 0\end{bmatrix}  \\ \\ &\xrightarrow{\huge{R_2\;\rightarrow\;R_2\,+\,R_1\,\times\,(-2)}} \begin{bmatrix} 1 & -1 & | & 0 \\ 0 & 0 & | & 0 \end{bmatrix} \; \;\; x_1 - x_2 = 0 \Rightarrow x_1 = x_2 \end{align}}$$

So
>$\large{x_1 =}$ basic variable
>$\large{x_2 =}$ free variable

The solution to $\large{(A - 4I)x = 0}$ is $\large{\begin{bmatrix} x_1 \\ x_2\end{bmatrix} = \begin{bmatrix} x_2 \\ x_2 \end{bmatrix} = x_2 \times \begin{bmatrix} \,1\, \\ 1\end{bmatrix}}$

Take $\large{x_2 = 1}$. We find one nonzero solution $\large{x = \begin{bmatrix} 1 \\ 1\end{bmatrix}}$.

Thus, $\large{\begin{bmatrix} 1 \\ 1\end{bmatrix}}$ is an eigenvector corresponding to $\large{\lambda = 4}$

____

Note that $\large{Ax = \lambda x \implies (A-\lambda I)x = 0}$

So, for a given eigenvalue, finding the eigenvector is equivalent to solving the homogenous system $\large{(A- \lambda I)x = 0}$.

#### Definition 2.
Eigenvectors corresponding to $\large{\lambda}$ are the elements of Nul($\large{A - \lambda I}$). Moreover, Nul($\large{(A - \lambda I)}$ is called the *eigenspace* of A corresponding to $\large{\lambda}$.

___
#### Example 4. 
Find a basis for the eigenspace corresponding to $\large{\lambda = 4}$ of

$$\large{\begin{bmatrix} 3 & 0 & 2 & 0 \\ 1 & 3 & 1 & 0 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 4 \end{bmatrix}}$$

#### Solution:
To find a basis of Nul($\large{A - \lambda I}$) = Nul($\large{A - 4I}$), we need to solve $\large{(A-4I)x = 0}$.
Augmented Matrix

$\large{\begin{bmatrix} A - 4I\,|\,0 \end{bmatrix} = \begin{bmatrix} \,3-4 & 0 & 2 & 0 & | & 0 \\ 1 & 3-4 & 1 & 0 & | & 0 \\ 0 & 1 & 1-4 & 0 & | & 0 \\ 0 & 0 & 0 & 4-4 & | & 0 \end{bmatrix}} = \begin{bmatrix} -1 & 0 & 2 & 0 & | & 0 \\ 1 & -1 & 1 & 0 & | & 0 \\ 0 & 1 & -3 & 0 & | & 0 \\ 0 & 1 & -3 & 0 & | & 0 \\ 0 & 0 & 0 & 0 & | & 0 \end{bmatrix}$

$$\large{\xrightarrow{\Huge{R_1\;\rightarrow\;(-1)\,\times\,R_1}} \begin{bmatrix} 1 & 0 & -2 & 0 & 0 \\ 1 & -1 & 1 & 0 & 0 \\ 0 & 1 & -3 & 0 & 0 \\ 0 & 0 & 0 & 0 & 0\end{bmatrix} \xrightarrow{\Huge{R_2\;\rightarrow\;R_2\,+\,R_1\,\times\,(-1)}} \underbrace{\begin{bmatrix} 1 & 0 & -2 & 0 & | & 0 \\ 0 & 1 & -3 & 0 & | & 0 \\ 0 & 0 & 0 & 0 & | & 0 \\ 0 & 0 & 0 & 0 & | & 0 \end{bmatrix}}_{\huge{REF!}}}$$
So, $\large{x_1}$ and $\large{x_2}$ are basic variables, and $\large{x_3}$ and $\large{x_4}$ are free variables. The general solution to $\large{(A - 4I)x = 0}$ is

$$\large{x = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \end{bmatrix} = \begin{bmatrix} 2x_3 \\ 3x_3 \\ x_3 \\ x_4 \end{bmatrix} = \begin{bmatrix} 2x_3 \\ 3x_3 \\ x_3 \\ 0\end{bmatrix} + \begin{bmatrix} 0 \\ 0 \\ 0 \\ x_4 \end{bmatrix} = x_3 \begin{bmatrix} 2 \\ 3 \\ 1 \\ 0 \end{bmatrix} + x_4 \begin{bmatrix} \,0\, \\ 0 \\ 0 \\ 1\end{bmatrix}}$$

Then $\large{\{\,V_1,\;V_2\,\}}$ forms a basis for Nul($\large{A-4I}$) (or *eigenspace* of matrix A corresponding to $\large{\lambda = 4}$).

#### Remark:

dim(Nul($\large{A - 4I}$)) = $\fbox{\large{2}}$

> dim(Nul($\large{M}$)) = *nullity* of M

____
### Theorem 1.
The eigenvalues of a triangular matrix are exactly the main diagonal entries.

___
#### Example 5.
Find the eigenvalues for the following matrix

$$\large{(a)\;A\;=\; \begin{bmatrix} 2 & 0 \\ 7 & 4 \end{bmatrix}\;\;\;\;\;\; (b)\;B\;=\;\begin{bmatrix} 4 & 0 \\ 8 & 0 \end{bmatrix}\;\;\;\;\;\;(c)\;C\;=\;\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}}$$
$$\large{(d)\;D\;=\;\begin{bmatrix} -4 & 3 & 6 \\ 0 & 1 & 6 \\ 0 & 0 & 9 \end{bmatrix}\;\;\;\;\;\;(e)\;E\;=\;\begin{bmatrix} 3 & 0 & 0 \\ 8 & 2 & 0 \\ 1 & 3 & -7\end{bmatrix}\;\;\;\;\;\;(f)\;M\;=\;\begin{bmatrix} 9 & 4 & 8 & 7 \\ 0 & 7 & 4 & 9 \\ 0 & 0 & -1 & 6 \\ 0 & 0 & 0 & 0\end{bmatrix}}$$
#### Solution:

>**(a)** $\large{A}$ is a triangular matrix. By Theorem 1, its eigenvalues are the main diagonal entries; i.e., $\large{\lambda = 2}$ and $\large{4}$.
>**(b)** $\large{B}$ is a triangular matrix. By Theorem 1, its eigenvalues are the main diagonal entries; i.e., $\large{\lambda = 4}$ and $\large{0}$.
>**(c)** $\large{C}$ is the identity matrix, which is also a triangular matrix. By Theorem 1, its eigenvalues are the main diagonal entries; i.e., $\large{\lambda = 1, 1}$ and $\large{1}$ 
>**(d)** $\large{D}$ is a triangular matrix. By Theorem 1, its eigenvalues are the main diagonal entries; i.e., $\large{\lambda = -4, 1,}$ and 9.
>**(e)** $\large{E}$ is a triangular matrix. By Theorem 1, its eigenvalues are the main diagonal entries; i.e., $\large{\lambda = 3, 2}$ and $\large{-7}$.
>**(f)** $\large{F}$ is a triangular matrix. By Theorem 1, its eigenvalues are the main diagonal entries; i.e., $\large{\lambda = 9, 7, -1}$

Connection of eigenvalues and eigenvectors to the IMT.

___
##### Recall:

A is invertible $\iff$ $\large{Ax = 0}$ only has the trivial solution ($\large{x = 0}$)

Thus,
A is NOT invertible $\iff$ $\large{Ax = 0}$ has some nontrivial solution $\large{x \neq 0}$

Then,

$\large{Ax = 0 \times x = 0}$    ($\large{x \neq 0}$)
which implies that 0 is an eigenvalue of A with an eigenvector x

#### Theorem 2.

$$\large{A\text{ is not invertible} \iff 0 \text{ is an eigenvalue of }A.}$$
#### Remark 3.

$$\large{ A \text{ is invertible} \iff 0\text{ is NOT an eigenvalue of } A}$$
Now we can add Remark 3. to the *Inverse Matrix Theorem* (IMT) as statement 16.

___

#### Question:

How do you determine if a scalar is an eigenvalue of the given matrix A?

#### Example 6.

Let $\large{A = \begin{bmatrix} 2 & 1 & 0 \\ 1 & 2 & 0 \\ 4 & 5 & 3 \end{bmatrix}}$.
.
	**(a)** Is $\large{\lambda = 0}$ an eigenvalue?
	**(b)** Is $\large{\lambda = -5}$ an eigenvalue?

#### Solution

$\large{\lambda}$ is an eigenvalue of $\large{A \iff (A - \lambda I)x = 0}$ has nontrivial solution $\large{x \neq 0 }$ 
$\large{\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \iff A - \lambda I}$         noninvertible
$\large{\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \iff \det(A - \lambda I) = 0}$

$\large{A - \lambda I = \begin{bmatrix} 2 & 1 & 0 \\ 1 & 2 & 0 \\ 4 & 5 & 3 \end{bmatrix} - \lambda \times \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 2-\lambda & 1 & 0 \\ 1 & 2-\lambda & 0 \\ 4 & 5 & 3 - \lambda \end{bmatrix}}$

$\large{\begin{align}&\implies \det(A - \lambda I) = \underbrace{(3-\lambda) \begin{vmatrix} 2-\lambda & 1 \\ 1 & 2-\lambda \end{vmatrix}}_{\text{cofactor expansion about 3rd column}} = (3-\lambda) \times ((2-\lambda)^2 - 1) \\ \\ &= (3-\lambda)\times(\lambda ^ 2 - 4\lambda + 4 - 1) = (3-\lambda)\times(\lambda^2 - 4 + 3)\end{align}}$

**(a)** Since we $\large{\det(A-\lambda I})\,\rvert_{\lambda = 0} = \large{(3 - 0) \times (0^2 - 4 \times 0 + 3) \neq 0 \implies \lambda = 0}$ is *NOT* an eigenvalue.

**(b)** Since $\large{\det(A - \lambda I)\, \rvert_{\lambda = 3} = (3-3)\times(3^2-4*3+3) = 0 \implies \lambda = 3 }$ is an eigenvalue.

___
### Question:
How do you find all eigenvalues of A?
#### Answer: [[5.2 Characteristic Equations]]
coming up...

___

#### Tags

>[!quote] Tags:
> [[Linear Algebra Information|Linear Algebra Information]]
